{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, re, pickle,tqdm\n",
    "import scipy.io\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import warnings, logging\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def RMSE(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def nested_dict(n):\n",
    "    if n == 1:\n",
    "        return defaultdict(lambda: np.ndarray(0))\n",
    "    else:\n",
    "        return defaultdict(lambda: nested_dict(n-1))\n",
    "    \n",
    "color_code = {\n",
    "    \"DET vs FullGradCam\":       \"blue\",\n",
    "    \"DET-GrpF vs FullGradCam\":  \"#0072BD\",\n",
    "    \"DET-GrpE vs FullGradCam\":  \"cyan\",\n",
    "    \n",
    "    \"EXP vs ODAM\":              \"red\",\n",
    "    \"EXP-GrpF vs ODAM\":         \"orange\",\n",
    "    \"EXP-GrpE vs ODAM\":         \"olive\",\n",
    "\n",
    "    \"PV vs FullGradCam\":        \"purple\",\n",
    "    \"PV-GrpF vs FullGradCam\":   \"pink\",\n",
    "    \"PV-GrpE vs FullGradCam\":   \"magenta\",\n",
    "}\n",
    "\n",
    "tnrfont = {'fontname':'Times New Roman'}\n",
    "\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_analysis = ['DET vs FullGradCam','EXP vs ODAM','PV vs FullGradCam']\n",
    "layer_name_mapping = ['model_1_act', 'model_2_cv1_act', 'model_2_cv2_act', 'model_2_m_0_cv1_act', 'model_2_m_0_cv2_act', 'model_2_cv3_act', 'model_3_act', 'model_4_cv1_act', 'model_4_cv2_act', 'model_4_m_0_cv1_act', 'model_4_m_0_cv2_act', 'model_4_m_1_cv1_act', 'model_4_m_1_cv2_act', 'model_4_cv3_act', 'model_5_act', 'model_6_cv1_act', 'model_6_cv2_act', 'model_6_m_0_cv1_act', 'model_6_m_0_cv2_act', 'model_6_m_1_cv1_act', 'model_6_m_1_cv2_act', 'model_6_m_2_cv1_act', 'model_6_m_2_cv2_act', 'model_6_cv3_act', 'model_7_act', 'model_8_cv1_act', 'model_8_cv2_act', 'model_8_m_0_cv1_act', 'model_8_m_0_cv2_act', 'model_8_cv3_act', 'model_9_cv1_act', 'model_9_cv2_act', 'model_10_act', 'model_13_cv1_act', 'model_13_cv2_act', 'model_13_m_0_cv1_act', 'model_13_m_0_cv2_act', 'model_13_cv3_act', 'model_14_act', 'model_17_cv1_act', 'model_17_cv2_act', 'model_17_m_0_cv1_act', 'model_17_m_0_cv2_act', 'model_17_cv3_act']\n",
    "\n",
    "special_layer_start = [\"model_9_cv1_act\" ,\"model_10_act\"]\n",
    "\n",
    "cogsci_layer = [\n",
    "    'model_23_cv3_act',\n",
    "    'model_21_act',\n",
    "    'model_20_cv3_act',\n",
    "    'model_18_act',\n",
    "    'model_17_cv3_act',\n",
    "    'model_14_act',\n",
    "    'model_13_cv3_act',\n",
    "    'model_10_act',\n",
    "    'model_9_cv2_act',\n",
    "    'model_8_cv3_act',\n",
    "    'model_7_act',\n",
    "    'model_6_cv3_act',\n",
    "    'model_5_act',\n",
    "    'model_4_cv3_act',\n",
    "    'model_3_act',\n",
    "    'model_2_cv3_act',\n",
    "    'model_1_act',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import time, pickle\n",
    "import itertools\n",
    "from itertools import chain\n",
    "\n",
    "hyperparameters = {\n",
    "'n_clusters': [None],\n",
    "'metric': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine'],\n",
    "'linkage': ['ward', 'complete', 'average', 'single'],\n",
    "}\n",
    "keys, values = zip(*hyperparameters.items())\n",
    "param_grid = [(idx, dict(zip(keys, v))) for idx, v in enumerate(itertools.product(*values))]\n",
    "print(len(param_grid))\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendro = dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "    clusters = defaultdict(list)\n",
    "\n",
    "    for leaf_label, leaf_color in zip(dendro['ivl'],dendro['leaves_color_list']):\n",
    "        clusters[leaf_color].append(leaf_label)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def extract_clusters_from_labels(cluster_labels, leaves):\n",
    "    # Group leaves based on their cluster labels\n",
    "    clusters = {}\n",
    "    for leaf, label in zip(leaves, cluster_labels):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(leaf+1)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "import time, sys\n",
    "\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "def fit_model(dfs, ax, analysis, idx, params):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # analysis = 'EXP vs ODAM'\n",
    "    # data = np.reshape(dfs[analysis].mean(axis=1),(-1, 1))\n",
    "    nan_imgs = set([dfs[analysis].columns[column] for row,column in zip(*np.where(dfs[analysis].isna()))])\n",
    "    if len(nan_imgs) > 0:\n",
    "        print(f'{analysis} dropped {len(nan_imgs)}')\n",
    "    data = dfs[analysis].drop(columns=nan_imgs) #TODO: auto detect and drop nan\n",
    "\n",
    "    if not params['n_clusters']:\n",
    "        params['distance_threshold'] = 0 # make sure we compute the full tree\n",
    "\n",
    "    model = AgglomerativeClustering(compute_distances=True,\n",
    "                                    **params\n",
    "                                    )\n",
    "    labels = model.fit_predict(data)\n",
    "    clusters = plot_dendrogram(model, ax=ax,truncate_mode=\"level\", labels=range(1,len(layer_name_mapping)+1))\n",
    "    # ax.set_title(f\"{params['metric']},{params['linkage']}\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    res = [{\"analysis\":analysis,\n",
    "            **params,\n",
    "            \"labels\":labels,\n",
    "            \"distances\":model.distances_,\n",
    "            \"time(s)\":end-start}]\n",
    "\n",
    "    return res, clusters\n",
    "\n",
    "cluster_labels = [\n",
    "\"*\",\n",
    "\"o\",\n",
    "\"v\",\n",
    "\"s\",\n",
    "\"X\",\n",
    "\"d\",\n",
    "\"p\",\n",
    "\"^\",\n",
    "\"<\",\n",
    "\">\",\n",
    "\"D\",\n",
    "\"P\",\n",
    "\"8\",\n",
    "\"h\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jinhanz/cs/xai/results/mscoco/240918_yolov5s_abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_imgs = list(PCC_all['DET vs FullGradCam']['model_1_act'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m analysis \u001b[38;5;129;01min\u001b[39;00m PCC_all_copy\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m PCC_all_copy[analysis]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m PCC_all_copy[analysis][layer]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m included_imgs:\n\u001b[1;32m     12\u001b[0m                 \u001b[38;5;28;01mdel\u001b[39;00m PCC_all[analysis][layer][img]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "for is_act in ['']:\n",
    "    for rescale_method in ['gaussian_sigma2','gaussian_sigma4']:\n",
    "        PCC_all = pickle.load(open(f'{root_dir}/mscoco_{is_act}{rescale_method}_PCC_all_conv.pickle','rb'))\n",
    "        RMSE_all = pickle.load(open(f'{root_dir}/mscoco_{is_act}{rescale_method}_RMSE_all_conv.pickle','rb'))\n",
    "\n",
    "        PCC_all_copy = PCC_all.copy()\n",
    "\n",
    "        for analysis in PCC_all_copy.keys():\n",
    "            for layer in PCC_all_copy[analysis].keys():\n",
    "                for img in PCC_all_copy[analysis][layer].keys():\n",
    "                    if img not in included_imgs:\n",
    "                        del PCC_all[analysis][layer][img]\n",
    "\n",
    "        PCC_layer_mean = defaultdict()\n",
    "        RMSE_layer_mean = defaultdict()\n",
    "\n",
    "        for analysis in PCC_all.keys():\n",
    "            PCC_layer_mean[analysis] = pd.DataFrame.from_dict(PCC_all[analysis]).mean(axis=0)\n",
    "            RMSE_layer_mean[analysis] = pd.DataFrame.from_dict(RMSE_all[analysis]).mean(axis=0)\n",
    "\n",
    "        dfs = {}\n",
    "        PCC_mean = {}\n",
    "\n",
    "        # reverse layer numbering\n",
    "        for analysis in focused_analysis:\n",
    "            df = pd.DataFrame.from_dict(PCC_all[analysis])\n",
    "\n",
    "            dfs[analysis] = df.T\n",
    "            PCC_mean[analysis] = df.T.mean(axis=1)\n",
    "\n",
    "            dfs[analysis].to_csv(f'{root_dir}/mscoco{is_act}_{rescale_method}_PCC_all_conv.csv',index=False)\n",
    "\n",
    "        membership = defaultdict()\n",
    "\n",
    "        for analysis in focused_analysis:\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=1,figsize=[6,6])\n",
    "            idx = 0\n",
    "            params = param_grid[0]\n",
    "            res, clusters = fit_model(dfs,axs,analysis,params[0],params[1])\n",
    "            membership[analysis] = clusters\n",
    "            # print(clusters)\n",
    "            if res != None: idx += 1\n",
    "            fig.suptitle(f\"MSCOCO {'Gradient' if is_act=='' else 'Activation'} {analysis} {rescale_method}\",fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.draw()\n",
    "\n",
    "        import matplotlib.lines as mlines\n",
    "        # Overall similarity\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.grid()\n",
    "        ax = plt.gca()\n",
    "        # plt.xlabel('Layer')\n",
    "        # plt.ylabel('PCC')\n",
    "        if is_act == '':\n",
    "            ylims = [0,0.7]\n",
    "        else:\n",
    "            ylims = [-0.5,0.7]\n",
    "        for analysis in focused_analysis:\n",
    "            plt.plot(np.arange(len(PCC_mean[analysis]))+1, list(PCC_mean[analysis]),label=analysis,c=color_code[analysis])\n",
    "            plt.xticks(np.arange(len(PCC_mean[analysis]))+1, [f\"{l+1}\" for l,layer in enumerate(layer_name_mapping)]) #rotation=-90\n",
    "            plt.ylim(ylims)\n",
    "            # plt.title(f\"Yolo-v5s MSCOCO\")e\n",
    "\n",
    "        # Highlight specific layers\n",
    "        for tick, label in zip(ax.get_xticks(), ax.get_xticklabels()):\n",
    "            if layer_name_mapping[tick-1] in cogsci_layer:\n",
    "                label.set_fontweight('bold')\n",
    "\n",
    "            if layer_name_mapping[tick-1] in special_layer_start:\n",
    "                label.set_color('red')\n",
    "\n",
    "        legend1 = plt.legend(fontsize=12, loc=0)\n",
    "        ax.add_artist(legend1)\n",
    "\n",
    "        for analysis in focused_analysis:\n",
    "            # print(analysis)\n",
    "            group_mean = {}\n",
    "            for g, group in membership[analysis].items():\n",
    "                inds = [idx-1 for idx in group]\n",
    "                layers = [layer_name_mapping[idx] for idx in inds]\n",
    "                mean = PCC_mean[analysis][layers].mean()\n",
    "                group_mean[g] = mean\n",
    "                # print(f\"{g} {mean} {sorted(group)}\")\n",
    "\n",
    "            # Sort by cluster mean similarity to human attention\n",
    "            group_rank = {k: rank for rank, (k, v) in enumerate(sorted(group_mean.items(), key=lambda item: item[1], reverse=True))}\n",
    "            # print(group_rank)\n",
    "\n",
    "            # print(labels[analysis])\n",
    "            for g, group in membership[analysis].items():\n",
    "                marker = cluster_labels[group_rank[g]]\n",
    "                for l in group:\n",
    "                    layer_name = layer_name_mapping[l-1]\n",
    "                    plt.plot(l,PCC_mean[analysis][layer_name],marker=marker,c=color_code[analysis],markersize=12,alpha=0.7)\n",
    "\n",
    "            # plt.plot(PCC_mean[analysis].index[12:18].values, PCC_mean[analysis].values[12:18], marker='o',fillstyle='none',label=analysis,c=color_code[analysis],alpha=alpha)\n",
    "\n",
    "        group_markers = []\n",
    "        group1_marker = mlines.Line2D([], [], color='black', marker=cluster_labels[0], linestyle='None',\n",
    "                                markersize=10, label='Group 1')\n",
    "        group_markers.append(group1_marker)\n",
    "        group2_marker = mlines.Line2D([], [], color='black', marker=cluster_labels[1], linestyle='None',\n",
    "                                markersize=10, label='Group 2')\n",
    "        group_markers.append(group2_marker)\n",
    "\n",
    "        if len([m for _, m in membership.items() if len(m)>=3])>0:\n",
    "            group3_marker = mlines.Line2D([], [], color='black', marker=cluster_labels[2], linestyle='None',\n",
    "                                    markersize=10, label='Group 3')\n",
    "            group_markers.append(group3_marker)\n",
    "\n",
    "        if len([m for _, m in membership.items() if len(m)>=4])>0:\n",
    "            group4_marker = mlines.Line2D([], [], color='black', marker=cluster_labels[3], linestyle='None',\n",
    "                                    markersize=10, label='Group 4')\n",
    "            group_markers.append(group4_marker)\n",
    "\n",
    "        legend2=plt.legend(handles=group_markers,loc=2)\n",
    "\n",
    "        plt.title(f\"MSCOCO {'Gradient' if is_act=='' else 'Activation'} {rescale_method}\")\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
